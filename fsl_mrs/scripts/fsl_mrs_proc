#!/usr/bin/env python

# fsl_mrs_proc - script for individual MRS preprocessing stages
#
# Author:   Will Clarke <william.clarke@ndcn.ox.ac.uk>
#           Saad Jbabdi <saad@fmrib.ox.ac.uk>
#
# Copyright (C) 2020 University of Oxford 
# SHBASECOPYRIGHT

# Quick imports
#import argparse
import configargparse

from fsl_mrs import __version__
from fsl_mrs.utils.splash import splash


def main():
    # Parse command-line arguments
    p = configargparse.ArgParser(add_config_file_help=False,description="FSL Magnetic Resonance Spectroscopy - Preprocessing")

    p.add_argument('-v','--version', action='version', version=__version__)

    sp = p.add_subparsers(title='subcommands', description='Preprocessing subcommands')

    # Coil combination subcommand
    ccparser = sp.add_parser('coilcombine',help='Combine coils.')
    ccparser.add_argument('--file',help='Uncombined coil data file(s)',type=str, nargs='+',required=True)
    ccparser.add_argument('--reference',help='Water unsuppressed reference data',type=str, nargs='+',required=False)
    ccparser.add_argument('--noprewhiten',help='Don''t prewhiten data before coil combination',action="store_false")
    ccparser.set_defaults(func=coilcombine)

    # Average subcommand
    avgparser = sp.add_parser('average',help='Average FIDs.')
    avgparser.add_argument('--file',help='MRS file(s)',type=str, nargs='+',required=True)
    avgparser.add_argument('--avgfiles',help='Average across files',action="store_true")
    avgparser.add_argument('--dim',help='Select dimension to average across',type=int)
    avgparser.set_defaults(func=average)

    #Align subcommand - frequency/phase alignment
    alignparser = sp.add_parser('align',help='Align FIDs.')
    alignparser.add_argument('--file',help='List of files to align',type=str, nargs='+',required=True)
    alignparser.add_argument('--ppm',help='ppm limits of alignment window (default=0.2->4.2)',type=float, nargs=2,metavar='<lower-limit upper-limit>',default=(0.2,4.2))
    alignparser.add_argument('--reference',help='Align to this reference data.',type=str,required=False)
    alignparser.set_defaults(func=align)

    #Align difference spectra subcommand - frequency/phase alignment
    alignDparser = sp.add_parser('align-diff',help='Align subspectra for differencing.')
    alignDparser.add_argument('--file',help='Subspectra 1 - List of files to align',type=str, nargs='+',required=True)
    alignDparser.add_argument('--reference',help='Subspectra 2 - List of files to align',type=str, nargs='+',required=True)
    alignDparser.add_argument('--ppm',help='ppm limits of alignment window (default=0.2->4.2)',type=float, nargs=2,metavar='<lower-limit upper-limit>',default=(0.2,4.2))
    alignDparser.add_argument('--diff_type',help='add (default) or subtract.',type=str,required=False,default='add')    
    alignDparser.set_defaults(func=aligndiff)

    # ECC subcommand - eddy current correction
    eccparser = sp.add_parser('ecc',help='Eddy current correction')     
    eccparser.add_argument('--file',help='Uncombined coil data file(s)',type=str, nargs='+',required=True)
    eccparser.add_argument('--reference',help='Phase reference data file(s)',type=str, nargs='+',required=True)
    eccparser.set_defaults(func=ecc)

    # remove subcommand - remove peak using HLSVD
    hlsvdparser = sp.add_parser('remove',help='Remove peak (default water) using HLSVD.') 
    hlsvdparser.add_argument('--file',help='Data file(s)',type=str, nargs='+',required=True)
    hlsvdparser.add_argument('--ppm',help='ppm limits of removal window',type=float, nargs=2,metavar='<lower-limit upper-limit>',default = [4.5,4.8])
    hlsvdparser.set_defaults(func=remove)

    # tshift subcommand - shift/resample in timedomain
    tshiftparser = sp.add_parser('tshift',help='shift/resample in timedomain.') 
    tshiftparser.add_argument('--file',help='Data file(s) to shift',type=str, nargs='+',required=True)
    tshiftparser.add_argument('--tshiftStart',help='Time shift at start (ms), negative pads with zeros, positive truncates',type=float,default = 0.0)
    tshiftparser.add_argument('--tshiftEnd',help='Time shift at end (ms), negative truncates, positive pads with zeros',type=float,default = 0.0)
    tshiftparser.add_argument('--samples',help='Resample to N points in FID.',type=int)
    tshiftparser.set_defaults(func=tshift)

    # truncate
    truncateparser = sp.add_parser('truncate',help='truncate by integer points in timedomain.') 
    truncateparser.add_argument('--file',help='Data file(s) to shift',type=str, nargs='+',required=True)
    truncateparser.add_argument('--points',help='Points to add/remove (+/-)',type=int,default = 0)
    truncateparser.add_argument('--pos',help=' ''first'' or ''last'' (default)',type=str,default = 'last')
    truncateparser.set_defaults(func=truncate)

    # apodize
    apodparser = sp.add_parser('apodize',help='Apodize FID.') 
    apodparser.add_argument('--file',help='Data file(s) to shift',type=str, nargs='+',required=True)
    apodparser.add_argument('--filter',help='Filter choice, either ''exp'' (default) or ''l2g''.',type=str,default = 'exp')
    apodparser.add_argument('--amount',help='Amount of broadening. In Hz for exp mode. Use space separated list for l2g.',type=float,nargs='+')
    apodparser.set_defaults(func=apodize)

    # fshift subcommand - shift in frequency domain
    fshiftparser = sp.add_parser('fshift',help='shift in frequency domain.') 
    fshiftparser.add_argument('--file',help='Data file(s) to shift',type=str, nargs='+',required=True)
    fshiftparser.add_argument('--shiftppm',help='Apply fixed shift (ppm scale)',type=float)
    fshiftparser.add_argument('--shifthz',help='Apply fixed shift (Hz scale)',type=float)
    fshiftparser.add_argument('--shiftRef',help='Shift to reference (default = Cr)',action="store_true")
    fshiftparser.add_argument('--ppm',help='Shift maximum point in this range to target (must specify --target).',type=float, nargs=2,metavar='<lower-limit upper-limit>',default=(2.8,3.2))
    fshiftparser.add_argument('--target',help='Target position (must be used with ppm). Default = 3.027',type=float,default=3.027)
    fshiftparser.set_defaults(func=fshift)

    # unlike subcomand - find FIDs that are unlike
    unlikeparser = sp.add_parser('unlike',help='Identify unlike FIDs.') 
    unlikeparser.add_argument('--file',help='Data file(s) to shift',type=str, nargs='+',required=True)
    unlikeparser.add_argument('--sd',help='Exclusion limit (# of SD from mean,default=1.96)',type=float,default=1.96)
    unlikeparser.add_argument('--iter',help='Iterations of algorithm.',type=int,default=2)
    unlikeparser.add_argument('--ppm',help='ppm limits of alignment window',type=float, nargs=2,metavar='<lower-limit upper-limit>',default=None)
    unlikeparser.add_argument('--outputbad',help='Output failed FIDs',action="store_true")
    unlikeparser.set_defaults(func=unlike)

    # Phasing - based on maximum point in range
    phaseparser = sp.add_parser('phase',help='Phase spectrum based on maximum point in range') 
    phaseparser.add_argument('--file',help='Data file(s) to shift',type=str, nargs='+',required=True)
    phaseparser.add_argument('--ppm',help='ppm limits of alignment window',type=float, nargs=2,metavar='<lower-limit upper-limit>',default=(2.8,3.2))
    phaseparser.set_defaults(func=phase)

    # subtraction - subtraction of FIDs
    subtractparser = sp.add_parser('subtract',help='Subtract two FIDs') 
    subtractparser.add_argument('--file',help='Two data files to subtract (second from first)',type=str, nargs=2,required=True)
    subtractparser.set_defaults(func=subtract)

    # add - addition of FIDs
    addparser = sp.add_parser('add',help='Add two FIDs') 
    addparser.add_argument('--file',help='Two data files to add',type=str, nargs=2,required=True)
    addparser.set_defaults(func=add)

    # Arguments not assiciated with subcommands
    required     = p.add_argument_group('required arguments')
    optional     = p.add_argument_group('additional options')

    # REQUIRED ARGUMENTS 
    required.add_argument('--output',
                          required=True,type=str,metavar='<str>',
                          help='output folder')

    # ADDITONAL OPTIONAL ARGUMENTS    
    optional.add_argument('--overwrite',action="store_true",
                          help='overwrite existing output folder')
    optional.add_argument('-r','--generateReports',action="store_true",
                          help='Generate HTML reports.')
    optional.add_argument('-i','--reportIndicies',type=int,nargs='+',default= [0],
                          help='Generate reports for selected inputs where multiple input files exist. Defaults to first (0). Specify as indices counting from 0.')
    optional.add_argument('--allreports',action="store_true",
                          help='Generate reports for all inputs. Overrides arguments to reportIndicies.')
    optional.add_argument('--conjugate',action="store_true",
                          help='apply conjugate to FID')
    optional.add_argument('--filename',type=str,metavar='<str>',
                          help='Override output file name.')    
    optional.add_argument('--verbose',action="store_true",
                          help='spit out verbose info')
    optional.add('--config', required=False, is_config_file=True, help='configuration file')

    # Parse command-line arguments
    args = p.parse_args()
    
    # Output kickass splash screen
    if args.verbose:
        splash(logo='mrs')
    
    # Parse file arguments    
    datafiles,reffiles = parsefilearguments(args)

    # Handle data loading
    dataList = loadData(datafiles,refdatafiles=reffiles,conjugate=args.conjugate)
    # Call function - pass dict like view of args for compatibility with other modules
    dataout = args.func(dataList,vars(args))
    if isinstance(dataout,tuple):
        additionalOutputs = dataout[1:]
        dataout = dataout[0]
    else:
        additionalOutputs = None

    # Write data
    writeData(dataout,args)

    # Output any additional arguments
    if additionalOutputs is not None:
        print(additionalOutputs)
    
# ######################################################
# Imports
import os #time,sys, shutil, warnings
import numpy as np
from fsl_mrs.utils import preproc
from fsl_mrs.utils.preproc.general import datacontainer
from fsl_mrs.utils.mrs_io import check_datatype
from fsl_mrs.utils.mrs_io import fsl_io
# ######################################################

def parsefilearguments(args):
    # print(args.file)
    datafiles = args.file
    if 'reference' in args:
        # print(args.reference)
        reffiles = args.reference
    else:
        reffiles = None

    return datafiles,reffiles

# Data I/O functions
def loadData(datafiles,refdatafiles=None,conjugate=False):
    """ Load data from a list of data files.

    The data must be of nifti format and the spatial dimensions are preserved.
    Optionaly loads one or many reference files.
    Can conjugate.
    """

    # Do a check on the first file passed. The data must be of nifti type. 
    if check_datatype(datafiles[0]) != 'NIFTI':
        raise ValueError(f'Preprocessing routines only handle NIFTI format data. Please convert your data using spec2nii. {datafiles[0]} was identified as {check_datatype(datafiles[0])}.')
    datalist = []
    # Load data into datacontainer
    if refdatafiles and len(refdatafiles)==len(datafiles):
        for f,r in zip(datafiles,refdatafiles):
            data,header = fsl_io.readNIFTI(f,squeezeSVS=False)
            ref,refheader = fsl_io.readNIFTI(r,squeezeSVS=False)
            if conjugate:
                data = data.conj()
                ref = ref.conj()

            datalist.append(datacontainer(data,
                                            header,
                                            os.path.basename(f),
                                            reference=ref,
                                            refheader=refheader,
                                            reffilename=os.path.basename(r)))
    elif refdatafiles and len(refdatafiles)==1:
        ref,refheader = fsl_io.readNIFTI(refdatafiles[0],squeezeSVS=False)
        if conjugate:
            ref = ref.conj()

        for f in datafiles:
            data,header = fsl_io.readNIFTI(f,squeezeSVS=False)
            if conjugate:
                data = data.conj()
                
            datalist.append(datacontainer(data,
                                                header,
                                                os.path.basename(f),
                                                reference=ref,
                                                refheader=refheader,
                                                reffilename=os.path.basename(refdatafiles[0])))
    elif refdatafiles and len(refdatafiles)!=len(datafiles):
        raise ValueError('Pass one reference file, an equal number of references as data files or none.')
    else:
        for f in datafiles:
            data,header = fsl_io.readNIFTI(f,squeezeSVS=False)
            if conjugate:
                data = data.conj()
            datalist.append(datacontainer(data,header,os.path.basename(f)))

    # Sort list based on datafilename property of datacontainer
    datalist.sort(key=lambda dataobj: dataobj.datafilename)
    return datalist

def writeData(dataobj,args):
    for iDx,d in enumerate(dataobj):
        if args.filename is None:
            fileout = os.path.join(args.output,d.datafilename)
        elif len(dataobj)==1:
            fileout = os.path.join(args.output,args.filename+'.nii.gz')
        else:
            fileout = os.path.join(args.output,args.filename+f'_{iDx:03.0f}.nii.gz')
        
        fsl_io.saveNIFTI(fileout,d.data,d.dataheader)

### Option functions ###
# Functions below here should be associated with a subcommand method specified above.
# They should call a method in preproc.py.

# Preprocessing functions    
def coilcombine(dataobj,args):
    dataout = []
    for idx,d in enumerate(dataobj):        
        combmain = np.zeros(d.data.shape[:4],dtype=np.complex128)
        for ijk in np.ndindex(d.data.shape[:3]):
            # If reference data is not loaded
            if d.reference is None:
                combmain[ijk] = preproc.combine_FIDs(d.data[ijk],'svd',do_prewhiten=~args['noprewhiten'])            
            else:
                # Otherwise                
                combW,refWeights = preproc.combine_FIDs(d.reference[ijk],'svd_weights',do_prewhiten=~args['noprewhiten'])
                combmain[ijk] = preproc.combine_FIDs(d.data[ijk],'weighted',weights=refWeights)
            
            if args['generateReports'] and np.prod(d.data.shape[:3])==1 and ((idx in args['reportIndicies']) or args['allreports']):
                from fsl_mrs.utils.preproc.combine import combine_FIDs_report
                reportDir = args['output']
                combine_FIDs_report(d.data[ijk],combmain[ijk],d.dataheader,ncha=d.data.shape[4],ppmlim = (0.0,6.0),method='svd',html=reportDir)
            # else - MRSI reporting is TODO

        # Reuse the file name as it's likely the coil uncombined data was all in one file anyway
        fileout = d.datafilename
        dataout.append(datacontainer(combmain,d.dataheader,fileout))

    return dataout

def average(dataobj,args):
    dataout = []
    if args['avgfiles']:        
        # Average data across all input files, outputing data the shape of any one file
        # combine_FIDs 'mean' takes mean across last dimension.
        allFileData = np.array([d.data for d in dataobj])
        meandata = preproc.combine_FIDs(allFileData.T,'mean')
        dataout.append(datacontainer(meandata,dataobj[0].dataheader,dataobj[0].datafilename))

        if args['generateReports'] and np.prod(dataobj[0].data.shape[:3])==1:
            from fsl_mrs.utils.preproc.combine import combine_FIDs_report
            reportDir = args['output']
            combine_FIDs_report([np.squeeze(d.data) for d in dataobj],
                                np.squeeze(meandata),
                                dataobj[0].dataheader,
                                method='mean',
                                html=reportDir)

    elif args['dim']:
        for idx,d in enumerate(dataobj):
            # permute the selected dimension to the last
            dataIn = np.moveaxis(d.data,args['dim'],-1)
            meandata = preproc.combine_FIDs(dataIn,'mean')
            meandata = np.moveaxis(meandata,-1,args['dim'])
            dataout.append(datacontainer(meandata,d.dataheader,d.datafilename))

            if args['generateReports'] and np.prod(d.data.shape[:3])==1 and ((idx in args['reportIndicies']) or args['allreports']):
                from fsl_mrs.utils.preproc.combine import combine_FIDs_report
                reportDir = args['output']
                dim = args['dim']
                combine_FIDs_report(dataIn,meandata,d.dataheader,ppmlim = (0.0,6.0),method=f'Mean along dim = {dim}',html=reportDir)
    else:
        raise RuntimeError('Neither avgfiles or dim arguments specified averaging dimension uncertain.')

    return dataout

def align(dataobj,args):

    bandwidth = dataobj[0].dataheader['bandwidth']
    centralFrequency = dataobj[0].dataheader['centralFrequency']*1E6
    allFIDs = [d.data for d in dataobj]
    for ijk in np.ndindex(dataobj[0].data.shape[:3]):    
        FIDlist = [fid[ijk] for fid in allFIDs]        

        tmpFIDS,phi,eps= preproc.phase_freq_align(FIDlist,bandwidth,centralFrequency,ppmlim=args['ppm'],niter=2,verbose=False,target=dataobj[0].reference)

        if args['generateReports'] and np.prod(dataobj[0].data.shape[:3])==1:
            from fsl_mrs.utils.preproc.align import phase_freq_align_report
            phase_freq_align_report(FIDlist,tmpFIDS,
                                    dataobj[0].dataheader,
                                    phi,eps,
                                    ppmlim=args['ppm'],
                                    html=args['output'])

        for iDx,fid in enumerate(tmpFIDS):
            allFIDs[iDx][ijk,...] = fid
        
    dataout = []
    for f,d in zip(allFIDs,dataobj):
        dataout.append(datacontainer(f,d.dataheader,d.datafilename))

    return dataout

def aligndiff(dataobj,args):
    # This currently contains a bit of a hack - I use reference
    # as a way to load the sub spectra that won't be shifted
    bandwidth = dataobj[0].dataheader['bandwidth']
    centralFrequency = dataobj[0].dataheader['centralFrequency']*1E6
    allFIDs0 = [d.data for d in dataobj]
    allFIDs1 = [d.reference for d in dataobj]
    for ijk in np.ndindex(dataobj[0].data.shape[:3]):    
        FIDlist0 = [fid[ijk] for fid in allFIDs0]        
        FIDlist1 = [fid[ijk] for fid in allFIDs1]

        tmpFIDS0,tmpFIDS1,phi,eps= preproc.phase_freq_align_diff(FIDlist0,FIDlist1,bandwidth,centralFrequency,ppmlim=args['ppm'],diffType=args['diff_type'])

        if args['generateReports'] and np.prod(dataobj[0].data.shape[:3])==1:
            from fsl_mrs.utils.preproc.align import phase_freq_align_diff_report   
            phase_freq_align_diff_report(FIDlist0,FIDlist1,tmpFIDS0,tmpFIDS1,
                                    dataobj[0].dataheader,
                                    phi,eps,
                                    ppmlim=args['ppm'],
                                    diffType=args['diff_type'],
                                    html=args['output'])

        for iDx,(fid0,fid1) in enumerate(zip(tmpFIDS0,tmpFIDS1)):
            allFIDs0[iDx][ijk,...] = fid0
            allFIDs1[iDx][ijk,...] = fid1
        
    dataout = []
    for f0,f1,d in zip(allFIDs0,allFIDs1,dataobj):
        dataout.append(datacontainer(f0,
                                d.dataheader,
                                d.datafilename,
                                reference=f1,
                                refheader=d.refheader,
                                reffilename=d.reffilename))

    return dataout


def ecc(dataobj,args):
    dataout = []
    for idx,d in enumerate(dataobj):
        corrected = np.zeros(d.data.shape,dtype=np.complex128)
        for ijk in np.ndindex(d.data.shape[:3]):
            corrected[ijk] = preproc.eddy_correct(d.data[ijk],d.reference[ijk])

            if args['generateReports'] and np.prod(d.data.shape[:3])==1 and ((idx in args['reportIndicies']) or args['allreports']):
                from fsl_mrs.utils.preproc.eddycorrect import eddy_correct_report
                reportDir = args['output']
                eddy_correct_report(d.data[ijk],corrected[ijk],d.reference[ijk],d.dataheader,html=args['output'])

        dataout.append(datacontainer(corrected,d.dataheader,d.datafilename))
    return dataout

def remove(dataobj,args):
    dataout = []
    for idx,d in enumerate(dataobj):
        limits = args['ppm']
        removed = np.zeros(d.data.shape,dtype=np.complex128)
        for ijk in np.ndindex(d.data.shape[:3]):
            removed[ijk] = preproc.hlsvd(d.data[ijk],
                                        d.dataheader['dwelltime'],
                                        d.dataheader['centralFrequency'],
                                        limits,
                                        limitUnits = 'ppm+shift')

            if args['generateReports'] and np.prod(d.data.shape[:3])==1 and ((idx in args['reportIndicies']) or args['allreports']):
                from fsl_mrs.utils.preproc.remove import hlsvd_report
                hlsvd_report(d.data[ijk],removed[ijk],d.dataheader,
                            limits,limitUnits = 'ppm+shift',html=args['output'])

        dataout.append(datacontainer(removed,d.dataheader,d.datafilename))
    return dataout

def tshift(dataobj,args):
    dataout = []
    for idx,d in enumerate(dataobj):
        shifted = np.zeros(d.data.shape,dtype=np.complex128)
        for ijk in np.ndindex(d.data.shape[:3]):
            shifted[ijk],newDT = preproc.timeshift(d.data[ijk],
                                        d.dataheader['dwelltime'],
                                        args['tshiftStart'],
                                        args['tshiftEnd'],
                                        args['samples'])

            if args['generateReports'] and np.prod(d.data.shape[:3])==1 and ((idx in args['reportIndicies']) or args['allreports']):
                from fsl_mrs.utils.preproc.shifting import shift_report
                from copy import deepcopy
                outhdr = deepcopy(d.dataheader)
                outhdr['dwelltime'] = newDT
                outhdr['bandwidth'] = 1/newDT
                shift_report(d.data[ijk],shifted[ijk],d.dataheader,outhdr,html=args['output'],function='tshift')

        d.dataheader['dwelltime'] = newDT
        d.dataheader['bandwidth'] = 1/newDT
        dataout.append(datacontainer(shifted,d.dataheader,d.datafilename))

    return dataout

def truncate(dataobj,args):
    dataout = []
    for idx,d in enumerate(dataobj):
        baseShape = list(d.data.shape)        
        baseShape[3] += args['points']
        newFID = np.zeros(baseShape,dtype=np.complex128)
        for ijk in np.ndindex(d.data.shape[:3]):
            if args['points']>0:
                newFID[ijk] = preproc.pad(d.data[ijk],np.abs(args['points']),args['pos'])
                repFunc = 'pad'
            elif args['points']<0:
                newFID[ijk] = preproc.truncate(d.data[ijk],np.abs(args['points']),args['pos'])
                repFunc = 'truncate'
            else:
                newFID[ijk] = d.data[ijk]
                repFunc = 'none'

            if args['generateReports'] and np.prod(d.data.shape[:3])==1 and ((idx in args['reportIndicies']) or args['allreports']):
                from fsl_mrs.utils.preproc.shifting import shift_report
                shift_report(d.data[ijk],newFID[ijk],d.dataheader,d.dataheader,html=args['output'],function=repFunc)
        
        dataout.append(datacontainer(newFID,d.dataheader,d.datafilename))
    return dataout

def apodize(dataobj,args):
    dataout = []
    for idx,d in enumerate(dataobj):
        broadened = np.zeros(d.data.shape,dtype=np.complex128)
        for ijk in np.ndindex(d.data.shape[:3]):
            broadened[ijk] = preproc.apodize(d.data[ijk],
                                d.dataheader['dwelltime'],
                                args['amount'],
                                filter= args['filter'])

        if args['generateReports'] and np.prod(d.data.shape[:3])==1 and ((idx in args['reportIndicies']) or args['allreports']):
                from fsl_mrs.utils.preproc.filtering import apodize_report
                apodize_report(d.data[ijk],broadened[ijk],d.dataheader,html=args['output'])

        dataout.append(datacontainer(broadened,d.dataheader,d.datafilename))

    return dataout


def fshift(dataobj,args):
    dataout = []
    for idx,d in enumerate(dataobj):
        if args['shiftppm'] is not None:            
            shift = args['shiftppm']*d.dataheader['centralFrequency']
            callMode = 'fixed'
        elif args['shifthz'] is not None:            
            shift = args['shifthz']
            callMode = 'fixed'
        elif args['shiftRef']:
            callMode = 'ref'
        else:
            raise ValueError('Specify --shiftppm or --shifthz.')
        shifted = np.zeros(d.data.shape,dtype=np.complex128)
        for ijk in np.ndindex(d.data.shape[:3]):
            if callMode == 'fixed':        
                shifted[ijk] = preproc.freqshift(d.data[ijk],
                                            d.dataheader['dwelltime'],
                                            shift)
                repFunc = 'freqshift'
            elif callMode == 'ref':        
                shifted[ijk],_ = preproc.shiftToRef(d.data[ijk],
                                            args['target'],
                                            d.dataheader['bandwidth'],
                                            d.dataheader['centralFrequency'],
                                            ppmlim=args['ppm'])
                repFunc = 'shiftToRef'

            if args['generateReports'] and np.prod(d.data.shape[:3])==1 and ((idx in args['reportIndicies']) or args['allreports']):
                from fsl_mrs.utils.preproc.shifting import shift_report
                shift_report(d.data[ijk],shifted[ijk],d.dataheader,d.dataheader,html=args['output'],function=repFunc)

        dataout.append(datacontainer(shifted,d.dataheader,d.datafilename))

    return dataout

def unlike(dataobj,args):
    if dataobj[0].data.shape[:3] != (1,1,1):
        raise ValueError('unlike subcommand only works on single voxel data. It is unclear what should happen with MRSI data.')

    FIDlist = [d.data[0,0,0,...] for d in dataobj] # Here we are assuming only SVS data.
    bandwidth = dataobj[0].dataheader['bandwidth']
    centralFrequency = dataobj[0].dataheader['centralFrequency']

    goodFIDs,badFIDs,gIndicies,bIndicies,metric = preproc.identifyUnlikeFIDs(FIDlist,bandwidth,centralFrequency,ppmlim=args['ppm'],sdlimit = args['sd'],iterations=args['iter'],shift=True)

    dataout = []
    for f,iDx in zip(goodFIDs,gIndicies):
        dataout.append(datacontainer(f,dataobj[iDx].dataheader,dataobj[iDx].datafilename))

    if args['outputbad']:
        for f,iDx in zip(badFIDs,bIndicies):
            dataout.append(datacontainer(f,dataobj[iDx].dataheader,dataobj[iDx].datafilename+'_FAIL'))

    if args['generateReports']:
        from fsl_mrs.utils.preproc.unlike import identifyUnlikeFIDs_report
        identifyUnlikeFIDs_report(goodFIDs,badFIDs,dataobj[0].dataheader,gIndicies
                            ,bIndicies,metric,ppmlim=args['ppm'],sdlimit = args['sd']
                            ,html=args['output'])

    return dataout

def phase(dataobj,args):
    dataout = []
    for idx,d in enumerate(dataobj):
        phased = np.zeros(d.data.shape,dtype=np.complex128)
        for ijk in np.ndindex(d.data.shape[:3]):    
            phased[ijk],_,pos = preproc.phaseCorrect(d.data[ijk],
                                d.dataheader['bandwidth'],
                                d.dataheader['centralFrequency']*1E6,
                                ppmlim = args['ppm'])

            if args['generateReports'] and np.prod(d.data.shape[:3])==1 and ((idx in args['reportIndicies']) or args['allreports']):
                from fsl_mrs.utils.preproc.phasing import phaseCorrect_report
                phaseCorrect_report(d.data[ijk],phased[ijk],d.dataheader,
                                    pos,ppmlim=args['ppm'],html=args['output'])

        dataout.append(datacontainer(phased,d.dataheader,d.datafilename))
    return dataout

def subtract(dataobj,args):
    dataout = []
    subtracted = preproc.subtract(dataobj[0].data,dataobj[1].data)
    dataout.append(datacontainer(subtracted,dataobj[0].dataheader,dataobj[0].datafilename))

    if args['generateReports']:
        from fsl_mrs.utils.preproc.general import add_subtract_report
        add_subtract_report(dataobj[0].data,dataobj[1].data,subtracted,dataobj[0].dataheader,ppmlim=(0.2,4.2),function='subtract',html=args['output'])
    return dataout

def add(dataobj,args):
    dataout = []
    added = preproc.add(dataobj[0].data,dataobj[1].data)
    dataout.append(datacontainer(added,dataobj[0].dataheader,dataobj[0].datafilename))

    if args['generateReports']:
        from fsl_mrs.utils.preproc.general import add_subtract_report
        add_subtract_report(dataobj[0].data,dataobj[1].data,added,dataobj[0].dataheader,ppmlim=(0.2,4.2),function='add',html=args['output'])

    return dataout

if __name__ == '__main__':
    main()
